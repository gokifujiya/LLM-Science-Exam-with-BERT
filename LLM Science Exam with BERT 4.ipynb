{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48957b88",
   "metadata": {
    "papermill": {
     "duration": 0.009627,
     "end_time": "2023-08-20T03:31:51.017162",
     "exception": false,
     "start_time": "2023-08-20T03:31:51.007535",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This competition involves **building a machine learning model to answer multiple-choice questions that were created by a large language model (LLM)**. The dataset consists of questions with **five possible answers (labeled A through E)**.\n",
    "\n",
    "The task is to **predict the top three most probable answers for each question in the test set**. For each question, there is one answer that is considered the most correct, according to the generating LLM.\n",
    "\n",
    "The specific files are:\n",
    "\n",
    "    train.csv: This file contains **200 example questions along with the correct answers**. This data should be used to train your machine learning model.\n",
    "\n",
    "    test.csv: This file contains the questions for which you must predict the answers. Note that the provided test.csv file is just a placeholder; the actual test data will be provided when your submission is scored. The true test data will have a similar format, but will consist of ~4,000 different questions.\n",
    "\n",
    "    sample_submission.csv: This file shows the correct format for submitting your predictions.\n",
    "\n",
    "For each question in test.csv, your model should predict the labels of the top three most probable answers, separated by spaces. These predictions should be stored in a new column called 'prediction'. The order of the labels matters, with the first label being the most likely answer according to your model, the second label being the second most likely, and so on.\n",
    "\n",
    "Finally, **your predictions should be written to a CSV file for submission**. The submission file should have two columns: 'id' and 'prediction'. The 'id' column should match the 'id' column in test.csv, and the 'prediction' column should contain your model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d8d015",
   "metadata": {
    "papermill": {
     "duration": 0.00797,
     "end_time": "2023-08-20T03:31:51.034079",
     "exception": false,
     "start_time": "2023-08-20T03:31:51.026109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load the Train Dataset\n",
    "\n",
    "First, we need to load the dataset using a library like Pandas. In this case, we have train_df which is a DataFrame that contains our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9bf948c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T03:31:51.052367Z",
     "iopub.status.busy": "2023-08-20T03:31:51.051593Z",
     "iopub.status.idle": "2023-08-20T03:31:51.101986Z",
     "shell.execute_reply": "2023-08-20T03:31:51.101070Z"
    },
    "papermill": {
     "duration": 0.062758,
     "end_time": "2023-08-20T03:31:51.104749",
     "exception": false,
     "start_time": "2023-08-20T03:31:51.041991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>MOND is a theory that reduces the observed mis...</td>\n",
       "      <td>MOND is a theory that increases the discrepanc...</td>\n",
       "      <td>MOND is a theory that explains the missing bar...</td>\n",
       "      <td>MOND is a theory that reduces the discrepancy ...</td>\n",
       "      <td>MOND is a theory that eliminates the observed ...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Which of the following is an accurate definiti...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The triskeles symbol was reconstructed as a fe...</td>\n",
       "      <td>The triskeles symbol is a representation of th...</td>\n",
       "      <td>The triskeles symbol is a representation of a ...</td>\n",
       "      <td>The triskeles symbol represents three interloc...</td>\n",
       "      <td>The triskeles symbol is a representation of th...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>What is the significance of regularization in ...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>What is the relation between the three moment ...</td>\n",
       "      <td>The three moment theorem expresses the relatio...</td>\n",
       "      <td>The three moment theorem is used to calculate ...</td>\n",
       "      <td>The three moment theorem describes the relatio...</td>\n",
       "      <td>The three moment theorem is used to calculate ...</td>\n",
       "      <td>The three moment theorem is used to derive the...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>What is the throttling process, and why is it ...</td>\n",
       "      <td>The throttling process is a steady flow of a f...</td>\n",
       "      <td>The throttling process is a steady adiabatic f...</td>\n",
       "      <td>The throttling process is a steady adiabatic f...</td>\n",
       "      <td>The throttling process is a steady flow of a f...</td>\n",
       "      <td>The throttling process is a steady adiabatic f...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>What happens to excess base metal as a solutio...</td>\n",
       "      <td>The excess base metal will often solidify, bec...</td>\n",
       "      <td>The excess base metal will often crystallize-o...</td>\n",
       "      <td>The excess base metal will often dissolve, bec...</td>\n",
       "      <td>The excess base metal will often liquefy, beco...</td>\n",
       "      <td>The excess base metal will often evaporate, be...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>What is the relationship between mass, force, ...</td>\n",
       "      <td>Mass is a property that determines the weight ...</td>\n",
       "      <td>Mass is an inertial property that determines a...</td>\n",
       "      <td>Mass is an inertial property that determines a...</td>\n",
       "      <td>Mass is an inertial property that determines a...</td>\n",
       "      <td>Mass is a property that determines the size of...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>What did Arthur Eddington discover about two o...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                             prompt  \\\n",
       "0      0  Which of the following statements accurately d...   \n",
       "1      1  Which of the following is an accurate definiti...   \n",
       "2      2  Which of the following statements accurately d...   \n",
       "3      3  What is the significance of regularization in ...   \n",
       "4      4  Which of the following statements accurately d...   \n",
       "..   ...                                                ...   \n",
       "195  195  What is the relation between the three moment ...   \n",
       "196  196  What is the throttling process, and why is it ...   \n",
       "197  197  What happens to excess base metal as a solutio...   \n",
       "198  198  What is the relationship between mass, force, ...   \n",
       "199  199  What did Arthur Eddington discover about two o...   \n",
       "\n",
       "                                                     A  \\\n",
       "0    MOND is a theory that reduces the observed mis...   \n",
       "1    Dynamic scaling refers to the evolution of sel...   \n",
       "2    The triskeles symbol was reconstructed as a fe...   \n",
       "3    Regularizing the mass-energy of an electron wi...   \n",
       "4    The angular spacing of features in the diffrac...   \n",
       "..                                                 ...   \n",
       "195  The three moment theorem expresses the relatio...   \n",
       "196  The throttling process is a steady flow of a f...   \n",
       "197  The excess base metal will often solidify, bec...   \n",
       "198  Mass is a property that determines the weight ...   \n",
       "199  Arthur Eddington showed that two of Einstein's...   \n",
       "\n",
       "                                                     B  \\\n",
       "0    MOND is a theory that increases the discrepanc...   \n",
       "1    Dynamic scaling refers to the non-evolution of...   \n",
       "2    The triskeles symbol is a representation of th...   \n",
       "3    Regularizing the mass-energy of an electron wi...   \n",
       "4    The angular spacing of features in the diffrac...   \n",
       "..                                                 ...   \n",
       "195  The three moment theorem is used to calculate ...   \n",
       "196  The throttling process is a steady adiabatic f...   \n",
       "197  The excess base metal will often crystallize-o...   \n",
       "198  Mass is an inertial property that determines a...   \n",
       "199  Arthur Eddington showed that two of Einstein's...   \n",
       "\n",
       "                                                     C  \\\n",
       "0    MOND is a theory that explains the missing bar...   \n",
       "1    Dynamic scaling refers to the evolution of sel...   \n",
       "2    The triskeles symbol is a representation of a ...   \n",
       "3    Regularizing the mass-energy of an electron wi...   \n",
       "4    The angular spacing of features in the diffrac...   \n",
       "..                                                 ...   \n",
       "195  The three moment theorem describes the relatio...   \n",
       "196  The throttling process is a steady adiabatic f...   \n",
       "197  The excess base metal will often dissolve, bec...   \n",
       "198  Mass is an inertial property that determines a...   \n",
       "199  Arthur Eddington showed that two of Einstein's...   \n",
       "\n",
       "                                                     D  \\\n",
       "0    MOND is a theory that reduces the discrepancy ...   \n",
       "1    Dynamic scaling refers to the non-evolution of...   \n",
       "2    The triskeles symbol represents three interloc...   \n",
       "3    Regularizing the mass-energy of an electron wi...   \n",
       "4    The angular spacing of features in the diffrac...   \n",
       "..                                                 ...   \n",
       "195  The three moment theorem is used to calculate ...   \n",
       "196  The throttling process is a steady flow of a f...   \n",
       "197  The excess base metal will often liquefy, beco...   \n",
       "198  Mass is an inertial property that determines a...   \n",
       "199  Arthur Eddington showed that two of Einstein's...   \n",
       "\n",
       "                                                     E answer  \n",
       "0    MOND is a theory that eliminates the observed ...      D  \n",
       "1    Dynamic scaling refers to the evolution of sel...      A  \n",
       "2    The triskeles symbol is a representation of th...      A  \n",
       "3    Regularizing the mass-energy of an electron wi...      C  \n",
       "4    The angular spacing of features in the diffrac...      D  \n",
       "..                                                 ...    ...  \n",
       "195  The three moment theorem is used to derive the...      C  \n",
       "196  The throttling process is a steady adiabatic f...      B  \n",
       "197  The excess base metal will often evaporate, be...      B  \n",
       "198  Mass is a property that determines the size of...      D  \n",
       "199  Arthur Eddington showed that two of Einstein's...      C  \n",
       "\n",
       "[200 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/train.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872fa3a4",
   "metadata": {
    "papermill": {
     "duration": 0.008734,
     "end_time": "2023-08-20T03:31:51.122704",
     "exception": false,
     "start_time": "2023-08-20T03:31:51.113970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenize and Format the Dataset\n",
    "\n",
    "The LLM understands only numbers, not raw text. Therefore, we need to **tokenize our dataset (convert the text into numbers)** and **format it in the way the LLM expects**. In the case of a multiple-choice question answering task, each sample in our dataset will consist of **a context (the question) and five possible responses (the options)**. We would use **a transformer's tokenizer** for this purpose. For example, **assuming the LLM we are using is based on BERT and tokenizer is a BERT tokenizer**.\n",
    "\n",
    "**The LLM needs to know the correct answer for each question** in the dataset to learn from it. In our dataset, the correct answer is given in the 'answer' column as a letter (A, B, C, D, or E). We need to **convert these letters into indices (0, 1, 2, 3, or 4)** because the LLM works with numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eb99a94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T03:31:51.141461Z",
     "iopub.status.busy": "2023-08-20T03:31:51.140499Z",
     "iopub.status.idle": "2023-08-20T03:31:55.125253Z",
     "shell.execute_reply": "2023-08-20T03:31:55.124134Z"
    },
    "papermill": {
     "duration": 3.997206,
     "end_time": "2023-08-20T03:31:55.128282",
     "exception": false,
     "start_time": "2023-08-20T03:31:51.131076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "MODEL_DIR = \"/kaggle/input/huggingface-bert/\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR + \"bert-large-uncased\")\n",
    "\n",
    "def encode(row):\n",
    "    # Format the context and the options.\n",
    "    prompt = str(row['prompt'])\n",
    "    options = [str(option) for option in row[['A', 'B', 'C', 'D', 'E']].values.tolist()]\n",
    "    \n",
    "    answer_mapping = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}\n",
    "    correct_answer_id = answer_mapping[row['answer']]\n",
    "\n",
    "    encoded_rows = []\n",
    "    # Tokenize the question and the options, and include the correct answer label.\n",
    "    for idx, option in enumerate(options):\n",
    "        text_pair = [prompt, option]\n",
    "        encoded = tokenizer(text_pair, truncation = True, padding = 'max_length', max_length = 512)\n",
    "        \n",
    "        # We set the label to 1 if this is the correct answer, otherwise 0.\n",
    "        encoded['labels'] = 1 if idx == correct_answer_id else 0\n",
    "        encoded_rows.append(encoded)\n",
    "\n",
    "    return encoded_rows\n",
    "\n",
    "encoded_train = []\n",
    "for _, row in train_df.iterrows():\n",
    "    encoded_train.extend(encode(row))\n",
    "\n",
    "# Now each item in encoded_train is a dictionary representing a single example.\n",
    "# We can convert it into a Dataset.\n",
    "encoded_train_dataset = Dataset.from_dict({key: [dic[key] for dic in encoded_train] for key in encoded_train[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c97873f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T03:31:55.149365Z",
     "iopub.status.busy": "2023-08-20T03:31:55.148827Z",
     "iopub.status.idle": "2023-08-20T03:31:55.155374Z",
     "shell.execute_reply": "2023-08-20T03:31:55.154428Z"
    },
    "papermill": {
     "duration": 0.019906,
     "end_time": "2023-08-20T03:31:55.158389",
     "exception": false,
     "start_time": "2023-08-20T03:31:55.138483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3480886",
   "metadata": {
    "papermill": {
     "duration": 0.008116,
     "end_time": "2023-08-20T03:31:55.175671",
     "exception": false,
     "start_time": "2023-08-20T03:31:55.167555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The encoded_train_dataset is an instance of the Dataset class from the Hugging Face datasets library. This dataset contains preprocessed and tokenized training data that we can use to train a machine learning model.\n",
    "\n",
    "The features field tells what kind of information each example in the dataset includes. Here, it includes:\n",
    "\n",
    "    input_ids: These are the tokenized inputs to the model. Each token in the input has been mapped to an ID using the vocabulary of the tokenizer.\n",
    "    \n",
    "    token_type_ids: These are used by some models (like BERT) to differentiate between different sequences in the input. For example, it can tell the model where the question ends and where the answer options begin.\n",
    "    \n",
    "    attention_mask: This is used to tell the model which parts of the input are actual content and which parts are padding (i.e., meaningless tokens added to make all inputs the same length).\n",
    "    \n",
    "    labels: These are the correct answers for each question. This is what the model is trying to predict.\n",
    "\n",
    "The num_rows field tells you that there are 1,000 examples in this dataset.\n",
    "\n",
    "Please note that the actual content of the dataset is not shown in this overview. we can access the data using indexing, for example \"encoded_train_dataset[0]\" to get the first example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe7b5e7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T03:31:55.194206Z",
     "iopub.status.busy": "2023-08-20T03:31:55.193424Z",
     "iopub.status.idle": "2023-08-20T03:31:55.197865Z",
     "shell.execute_reply": "2023-08-20T03:31:55.197061Z"
    },
    "papermill": {
     "duration": 0.015829,
     "end_time": "2023-08-20T03:31:55.199835",
     "exception": false,
     "start_time": "2023-08-20T03:31:55.184006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#encoded_train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bae3386",
   "metadata": {
    "papermill": {
     "duration": 0.008524,
     "end_time": "2023-08-20T03:31:55.216901",
     "exception": false,
     "start_time": "2023-08-20T03:31:55.208377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# See the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb398d71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T03:31:55.234998Z",
     "iopub.status.busy": "2023-08-20T03:31:55.234714Z",
     "iopub.status.idle": "2023-08-20T03:31:55.245050Z",
     "shell.execute_reply": "2023-08-20T03:31:55.242805Z"
    },
    "papermill": {
     "duration": 0.021984,
     "end_time": "2023-08-20T03:31:55.247307",
     "exception": false,
     "start_time": "2023-08-20T03:31:55.225323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_train_dataset['labels'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d430d4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T03:31:55.267009Z",
     "iopub.status.busy": "2023-08-20T03:31:55.266175Z",
     "iopub.status.idle": "2023-08-20T03:31:55.273906Z",
     "shell.execute_reply": "2023-08-20T03:31:55.272791Z"
    },
    "papermill": {
     "duration": 0.020526,
     "end_time": "2023-08-20T03:31:55.276042",
     "exception": false,
     "start_time": "2023-08-20T03:31:55.255516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer_mapping = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}\n",
    "train_labels = train_df['answer'].map(answer_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89707e56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T03:31:55.294419Z",
     "iopub.status.busy": "2023-08-20T03:31:55.294162Z",
     "iopub.status.idle": "2023-08-20T03:31:55.302122Z",
     "shell.execute_reply": "2023-08-20T03:31:55.301197Z"
    },
    "papermill": {
     "duration": 0.019272,
     "end_time": "2023-08-20T03:31:55.304215",
     "exception": false,
     "start_time": "2023-08-20T03:31:55.284943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3\n",
       "1      0\n",
       "2      0\n",
       "3      2\n",
       "4      3\n",
       "      ..\n",
       "195    2\n",
       "196    1\n",
       "197    1\n",
       "198    3\n",
       "199    2\n",
       "Name: answer, Length: 200, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c09d7b8",
   "metadata": {
    "papermill": {
     "duration": 0.008492,
     "end_time": "2023-08-20T03:31:55.321535",
     "exception": false,
     "start_time": "2023-08-20T03:31:55.313043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Initialize and Train the Model\n",
    "\n",
    "We need to initialize the LLM for fine-tuning. We use a version of the LLM that is **specifically designed for multiple-choice tasks**.\n",
    "\n",
    "**This time we use BERT-large.** The primary difference between the \"base\" and \"large\" versions of BERT models lies in **their size, which is reflected in the number of parameters they have, the number of transformer layers (i.e., the \"depth\" of the network), and the size of these layers (i.e., the \"width\" of the network)**. This directly impacts the model's capacity to learn from data, its computational requirements, and its performance on different tasks.\n",
    "\n",
    "Here's a quick comparison:\n",
    "\n",
    "    BERT-base: BERT-base models are smaller versions, with 12 transformer layers, each with a hidden size of 768, and 12 attention heads. This results in a total of about 110 million parameters.\n",
    "\n",
    "    BERT-large: BERT-large models are much bigger, with 24 transformer layers, each with a hidden size of 1024, and 16 attention heads. This results in a total of about 340 million parameters.\n",
    "\n",
    "**Because BERT-large models are larger and have more parameters, they have a greater capacity to learn and model complex patterns in data.** As a result, they typically perform better on tasks involving understanding natural language. **However, they also require more computational resources (both for training and inference), and the improvements they provide may not always justify the increased computational cost**, depending on the specific application and available resources.\n",
    "\n",
    "**The uncased model does not distinguish between uppercase and lowercase letters (it lowercases all input before tokenizing), whereas the cased model does keep the original letter cases.**\n",
    "\n",
    "**Training LLMs from scratch is computationally expensive and can take a very long time, even on multiple GPUs**. In practice, **we often use a pre-trained LLM and fine-tune it on our specific task, which is much quicker and requires less computational resources**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742649a2",
   "metadata": {
    "papermill": {
     "duration": 0.008401,
     "end_time": "2023-08-20T03:31:55.338819",
     "exception": false,
     "start_time": "2023-08-20T03:31:55.330418",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Compute Metrics\n",
    "\n",
    "This code **computes the average precision at 3 for each question, then takes the mean of these scores**. The average_precision_at_3 function returns the precision at the rank of the correct label if it is within the top 3 predictions, or 0 otherwise. It uses the index method to find the rank of the correct label, adding 1 because index is 0-based while ranks are 1-based. The try/except block handles the case where the correct label is not in the top 3 predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d7bc3b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T03:31:55.357523Z",
     "iopub.status.busy": "2023-08-20T03:31:55.356811Z",
     "iopub.status.idle": "2023-08-20T03:31:55.364266Z",
     "shell.execute_reply": "2023-08-20T03:31:55.363330Z"
    },
    "papermill": {
     "duration": 0.01899,
     "end_time": "2023-08-20T03:31:55.366502",
     "exception": false,
     "start_time": "2023-08-20T03:31:55.347512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions\n",
    "    map3 = mean_average_precision_at_3(labels, preds)\n",
    "    return {\n",
    "        'map3': map3\n",
    "    }\n",
    "\n",
    "def mean_average_precision_at_3(labels, preds):\n",
    "    ap3s = [average_precision_at_3(label, pred) for label, pred in zip(labels, preds)]\n",
    "    return np.mean(ap3s)\n",
    "\n",
    "def average_precision_at_3(label, pred):\n",
    "    pred_top3 = pred[:3]\n",
    "    indices = np.where(pred_top3 == label)[0]\n",
    "    if indices.size > 0:\n",
    "        # np.where returns 0-based indices, so we add 1 to get the rank.\n",
    "        return 1 / (indices[0] + 1)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d2359d",
   "metadata": {
    "papermill": {
     "duration": 0.00829,
     "end_time": "2023-08-20T03:31:55.383191",
     "exception": false,
     "start_time": "2023-08-20T03:31:55.374901",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train the Model with Cross-Validation\n",
    "\n",
    "Finally, we can train the model using a library like Hugging Face's Transformers, which provides an easy-to-use Trainer class. We need to provide our encoded dataset, the correct labels, and some training arguments to the Trainer, and then call the train method to start training.\n",
    "\n",
    "The Hugging Face's Trainer class does not support cross-validation directly. However, we can implement cross-validation yourself by creating multiple splits of your dataset and training a model on each split. **Scikit-Learn's KFold class** can help you create the splits.\n",
    "\n",
    "In this example, we are using **3-fold cross-validation instead of 5-fold for the limitation on the available GPU**, which means the data is split into 3 subsets (folds). **The model is trained 3 times, each time on 2 of the subsets and evaluated on the remaining subset.**\n",
    "\n",
    "For the same reason, **the number of epochs and tha batch size are limited to 3 and 1**, respectively.\n",
    "   \n",
    "### **Therefore, the learning rate should be the great factor to determine the performance of the model. Please compare with previous versions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2fef16c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T03:31:55.402173Z",
     "iopub.status.busy": "2023-08-20T03:31:55.401391Z",
     "iopub.status.idle": "2023-08-20T04:16:36.276293Z",
     "shell.execute_reply": "2023-08-20T04:16:36.274787Z"
    },
    "papermill": {
     "duration": 2680.890326,
     "end_time": "2023-08-20T04:16:36.282201",
     "exception": false,
     "start_time": "2023-08-20T03:31:55.391875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /kaggle/input/huggingface-bert/bert-large-uncased were not used when initializing BertForMultipleChoice: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at /kaggle/input/huggingface-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='999' max='999' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [999/999 13:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.870700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval result: {'eval_loss': 0.974872350692749, 'eval_map3': 0.0, 'eval_runtime': 39.8061, 'eval_samples_per_second': 8.391, 'eval_steps_per_second': 1.055, 'epoch': 3.0}\n",
      "FOLD 1\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /kaggle/input/huggingface-bert/bert-large-uncased were not used when initializing BertForMultipleChoice: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at /kaggle/input/huggingface-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='999' max='999' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [999/999 13:46, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.848500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval result: {'eval_loss': 0.7193840146064758, 'eval_map3': 0.0, 'eval_runtime': 39.6063, 'eval_samples_per_second': 8.408, 'eval_steps_per_second': 1.06, 'epoch': 3.0}\n",
      "FOLD 2\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /kaggle/input/huggingface-bert/bert-large-uncased were not used when initializing BertForMultipleChoice: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at /kaggle/input/huggingface-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='999' max='999' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [999/999 13:46, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.820400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval result: {'eval_loss': 0.9192283153533936, 'eval_map3': 0.0, 'eval_runtime': 39.7091, 'eval_samples_per_second': 8.386, 'eval_steps_per_second': 1.058, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Disable wandb globally.\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "kfold = KFold(n_splits = 3)\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(encoded_train_dataset)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "    \n",
    "    # Subset the dataset.\n",
    "    train_subset = encoded_train_dataset.select(train_ids)\n",
    "    test_subset = encoded_train_dataset.select(test_ids)\n",
    "    \n",
    "    # Create a new instance of the model for each fold.\n",
    "    model = AutoModelForMultipleChoice.from_pretrained(MODEL_DIR + \"bert-large-uncased\")\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir = f'./finetuned_bert_fold_{fold}',  # output directory for each fold\n",
    "        num_train_epochs = 3,\n",
    "        per_device_train_batch_size = 1,\n",
    "        learning_rate = 2.1e-5,\n",
    "        gradient_accumulation_steps = 2,\n",
    "        report_to = [],  # Disable all integrations.\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model = model,\n",
    "        args = training_args,\n",
    "        train_dataset = train_subset,\n",
    "        eval_dataset = test_subset,  # Use the test subset for evaluation.\n",
    "        compute_metrics = compute_metrics,  # optional function to compute metrics for evaluation\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # We can evaluate and save the model after training if we wish.\n",
    "    eval_result = trainer.evaluate(eval_dataset = test_subset)\n",
    "    print(f\"Eval result: {eval_result}\")\n",
    "    trainer.save_model(f'./finetuned_bert_fold_{fold}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc754588",
   "metadata": {
    "papermill": {
     "duration": 0.053445,
     "end_time": "2023-08-20T04:16:36.375231",
     "exception": false,
     "start_time": "2023-08-20T04:16:36.321786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predict the Test Data\n",
    "\n",
    "We will make predictions with the trained model and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a607ada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:16:36.482118Z",
     "iopub.status.busy": "2023-08-20T04:16:36.481592Z",
     "iopub.status.idle": "2023-08-20T04:16:36.542186Z",
     "shell.execute_reply": "2023-08-20T04:16:36.540437Z"
    },
    "papermill": {
     "duration": 0.119607,
     "end_time": "2023-08-20T04:16:36.546386",
     "exception": false,
     "start_time": "2023-08-20T04:16:36.426779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>MOND is a theory that reduces the observed mis...</td>\n",
       "      <td>MOND is a theory that increases the discrepanc...</td>\n",
       "      <td>MOND is a theory that explains the missing bar...</td>\n",
       "      <td>MOND is a theory that reduces the discrepancy ...</td>\n",
       "      <td>MOND is a theory that eliminates the observed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Which of the following is an accurate definiti...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The triskeles symbol was reconstructed as a fe...</td>\n",
       "      <td>The triskeles symbol is a representation of th...</td>\n",
       "      <td>The triskeles symbol is a representation of a ...</td>\n",
       "      <td>The triskeles symbol represents three interloc...</td>\n",
       "      <td>The triskeles symbol is a representation of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>What is the significance of regularization in ...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>What is the relation between the three moment ...</td>\n",
       "      <td>The three moment theorem expresses the relatio...</td>\n",
       "      <td>The three moment theorem is used to calculate ...</td>\n",
       "      <td>The three moment theorem describes the relatio...</td>\n",
       "      <td>The three moment theorem is used to calculate ...</td>\n",
       "      <td>The three moment theorem is used to derive the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>What is the throttling process, and why is it ...</td>\n",
       "      <td>The throttling process is a steady flow of a f...</td>\n",
       "      <td>The throttling process is a steady adiabatic f...</td>\n",
       "      <td>The throttling process is a steady adiabatic f...</td>\n",
       "      <td>The throttling process is a steady flow of a f...</td>\n",
       "      <td>The throttling process is a steady adiabatic f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>What happens to excess base metal as a solutio...</td>\n",
       "      <td>The excess base metal will often solidify, bec...</td>\n",
       "      <td>The excess base metal will often crystallize-o...</td>\n",
       "      <td>The excess base metal will often dissolve, bec...</td>\n",
       "      <td>The excess base metal will often liquefy, beco...</td>\n",
       "      <td>The excess base metal will often evaporate, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>What is the relationship between mass, force, ...</td>\n",
       "      <td>Mass is a property that determines the weight ...</td>\n",
       "      <td>Mass is an inertial property that determines a...</td>\n",
       "      <td>Mass is an inertial property that determines a...</td>\n",
       "      <td>Mass is an inertial property that determines a...</td>\n",
       "      <td>Mass is a property that determines the size of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>What did Arthur Eddington discover about two o...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                             prompt  \\\n",
       "0      0  Which of the following statements accurately d...   \n",
       "1      1  Which of the following is an accurate definiti...   \n",
       "2      2  Which of the following statements accurately d...   \n",
       "3      3  What is the significance of regularization in ...   \n",
       "4      4  Which of the following statements accurately d...   \n",
       "..   ...                                                ...   \n",
       "195  195  What is the relation between the three moment ...   \n",
       "196  196  What is the throttling process, and why is it ...   \n",
       "197  197  What happens to excess base metal as a solutio...   \n",
       "198  198  What is the relationship between mass, force, ...   \n",
       "199  199  What did Arthur Eddington discover about two o...   \n",
       "\n",
       "                                                     A  \\\n",
       "0    MOND is a theory that reduces the observed mis...   \n",
       "1    Dynamic scaling refers to the evolution of sel...   \n",
       "2    The triskeles symbol was reconstructed as a fe...   \n",
       "3    Regularizing the mass-energy of an electron wi...   \n",
       "4    The angular spacing of features in the diffrac...   \n",
       "..                                                 ...   \n",
       "195  The three moment theorem expresses the relatio...   \n",
       "196  The throttling process is a steady flow of a f...   \n",
       "197  The excess base metal will often solidify, bec...   \n",
       "198  Mass is a property that determines the weight ...   \n",
       "199  Arthur Eddington showed that two of Einstein's...   \n",
       "\n",
       "                                                     B  \\\n",
       "0    MOND is a theory that increases the discrepanc...   \n",
       "1    Dynamic scaling refers to the non-evolution of...   \n",
       "2    The triskeles symbol is a representation of th...   \n",
       "3    Regularizing the mass-energy of an electron wi...   \n",
       "4    The angular spacing of features in the diffrac...   \n",
       "..                                                 ...   \n",
       "195  The three moment theorem is used to calculate ...   \n",
       "196  The throttling process is a steady adiabatic f...   \n",
       "197  The excess base metal will often crystallize-o...   \n",
       "198  Mass is an inertial property that determines a...   \n",
       "199  Arthur Eddington showed that two of Einstein's...   \n",
       "\n",
       "                                                     C  \\\n",
       "0    MOND is a theory that explains the missing bar...   \n",
       "1    Dynamic scaling refers to the evolution of sel...   \n",
       "2    The triskeles symbol is a representation of a ...   \n",
       "3    Regularizing the mass-energy of an electron wi...   \n",
       "4    The angular spacing of features in the diffrac...   \n",
       "..                                                 ...   \n",
       "195  The three moment theorem describes the relatio...   \n",
       "196  The throttling process is a steady adiabatic f...   \n",
       "197  The excess base metal will often dissolve, bec...   \n",
       "198  Mass is an inertial property that determines a...   \n",
       "199  Arthur Eddington showed that two of Einstein's...   \n",
       "\n",
       "                                                     D  \\\n",
       "0    MOND is a theory that reduces the discrepancy ...   \n",
       "1    Dynamic scaling refers to the non-evolution of...   \n",
       "2    The triskeles symbol represents three interloc...   \n",
       "3    Regularizing the mass-energy of an electron wi...   \n",
       "4    The angular spacing of features in the diffrac...   \n",
       "..                                                 ...   \n",
       "195  The three moment theorem is used to calculate ...   \n",
       "196  The throttling process is a steady flow of a f...   \n",
       "197  The excess base metal will often liquefy, beco...   \n",
       "198  Mass is an inertial property that determines a...   \n",
       "199  Arthur Eddington showed that two of Einstein's...   \n",
       "\n",
       "                                                     E  \n",
       "0    MOND is a theory that eliminates the observed ...  \n",
       "1    Dynamic scaling refers to the evolution of sel...  \n",
       "2    The triskeles symbol is a representation of th...  \n",
       "3    Regularizing the mass-energy of an electron wi...  \n",
       "4    The angular spacing of features in the diffrac...  \n",
       "..                                                 ...  \n",
       "195  The three moment theorem is used to derive the...  \n",
       "196  The throttling process is a steady adiabatic f...  \n",
       "197  The excess base metal will often evaporate, be...  \n",
       "198  Mass is a property that determines the size of...  \n",
       "199  Arthur Eddington showed that two of Einstein's...  \n",
       "\n",
       "[200 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/test.csv\")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e72ee8",
   "metadata": {
    "papermill": {
     "duration": 0.054276,
     "end_time": "2023-08-20T04:16:36.658491",
     "exception": false,
     "start_time": "2023-08-20T04:16:36.604215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Encoding: This is the step we are performing with our encode_test() function. Each prompt and option pair is tokenized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3901153",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:16:36.782642Z",
     "iopub.status.busy": "2023-08-20T04:16:36.780637Z",
     "iopub.status.idle": "2023-08-20T04:16:38.185829Z",
     "shell.execute_reply": "2023-08-20T04:16:38.184798Z"
    },
    "papermill": {
     "duration": 1.475068,
     "end_time": "2023-08-20T04:16:38.188830",
     "exception": false,
     "start_time": "2023-08-20T04:16:36.713762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [[input_ids, token_type_ids, attention_mask], ...\n",
       "1      [[input_ids, token_type_ids, attention_mask], ...\n",
       "2      [[input_ids, token_type_ids, attention_mask], ...\n",
       "3      [[input_ids, token_type_ids, attention_mask], ...\n",
       "4      [[input_ids, token_type_ids, attention_mask], ...\n",
       "                             ...                        \n",
       "195    [[input_ids, token_type_ids, attention_mask], ...\n",
       "196    [[input_ids, token_type_ids, attention_mask], ...\n",
       "197    [[input_ids, token_type_ids, attention_mask], ...\n",
       "198    [[input_ids, token_type_ids, attention_mask], ...\n",
       "199    [[input_ids, token_type_ids, attention_mask], ...\n",
       "Length: 200, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_test(example):\n",
    "    # Format the context and the options.\n",
    "    prompt = str(example['prompt'])\n",
    "    options = [str(option) for option in example[['A', 'B', 'C', 'D', 'E']].values.tolist()]\n",
    "    examples = []\n",
    "\n",
    "    # Tokenize the question and the options.\n",
    "    for option in options:\n",
    "        text_pair = [prompt, option]\n",
    "        encoded = tokenizer(text_pair, truncation = True, padding = 'max_length', max_length = 512)\n",
    "        examples.append(encoded)\n",
    "\n",
    "    return examples\n",
    "\n",
    "encoded_test_df = test_df.apply(encode_test, axis = 1)\n",
    "encoded_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61ff3c3",
   "metadata": {
    "papermill": {
     "duration": 0.015856,
     "end_time": "2023-08-20T04:16:38.222619",
     "exception": false,
     "start_time": "2023-08-20T04:16:38.206763",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Prediction: Next, we need to loop over the encoded inputs, feed them to the model, and store the model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab3d6186",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:16:38.257238Z",
     "iopub.status.busy": "2023-08-20T04:16:38.256704Z",
     "iopub.status.idle": "2023-08-20T04:18:33.128632Z",
     "shell.execute_reply": "2023-08-20T04:18:33.127514Z"
    },
    "papermill": {
     "duration": 114.892458,
     "end_time": "2023-08-20T04:18:33.131600",
     "exception": false,
     "start_time": "2023-08-20T04:16:38.239142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if a GPU is available and if not, default to CPU.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Reduce batch size and limit sequence length.\n",
    "batch_size = 2\n",
    "sequence_length = 128\n",
    "\n",
    "predictions = []\n",
    "for row in encoded_test_df:\n",
    "    # Truncate or pad sequences to a fixed length.\n",
    "    row = row[:sequence_length]\n",
    "\n",
    "    # Create tensors for input_ids and attention_mask.\n",
    "    input_ids = torch.tensor([item['input_ids'] for item in row], dtype = torch.long).to(device)\n",
    "    attention_mask = torch.tensor([item['attention_mask'] for item in row], dtype = torch.long).to(device)\n",
    "\n",
    "    # Run inference with reduced batch size.\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids = input_ids, attention_mask = attention_mask)\n",
    "\n",
    "    predictions.append(outputs.logits.detach().cpu().numpy())\n",
    "\n",
    "    # Free GPU memory by deleting tensors.\n",
    "    del input_ids, attention_mask, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af3a01f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:18:33.158136Z",
     "iopub.status.busy": "2023-08-20T04:18:33.157823Z",
     "iopub.status.idle": "2023-08-20T04:18:33.165916Z",
     "shell.execute_reply": "2023-08-20T04:18:33.164787Z"
    },
    "papermill": {
     "duration": 0.023671,
     "end_time": "2023-08-20T04:18:33.167885",
     "exception": false,
     "start_time": "2023-08-20T04:18:33.144214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.586057 , -3.0604074],\n",
       "        [ 1.586057 , -2.964359 ],\n",
       "        [ 1.586057 , -3.067085 ],\n",
       "        [ 1.586057 , -2.9638898],\n",
       "        [ 1.586057 , -3.0421693]], dtype=float32),\n",
       " array([[ 1.5568192, -2.9404914],\n",
       "        [ 1.5568192, -2.9486485],\n",
       "        [ 1.5568192, -2.9299943],\n",
       "        [ 1.5568192, -2.946149 ],\n",
       "        [ 1.5568192, -2.9360266]], dtype=float32),\n",
       " array([[ 1.6091564, -2.8757195],\n",
       "        [ 1.6091564, -3.029059 ],\n",
       "        [ 1.6091564, -3.003296 ],\n",
       "        [ 1.6091564, -3.0344126],\n",
       "        [ 1.6091564, -3.077248 ]], dtype=float32),\n",
       " array([[ 1.6203096, -2.9147065],\n",
       "        [ 1.6203096, -2.9702091],\n",
       "        [ 1.6203096, -2.944651 ],\n",
       "        [ 1.6203096, -2.9809136],\n",
       "        [ 1.6203096, -2.9902933]], dtype=float32),\n",
       " array([[ 1.5371877, -2.7604625],\n",
       "        [ 1.5371877, -2.7619119],\n",
       "        [ 1.5371877, -2.756531 ],\n",
       "        [ 1.5371877, -2.7581959],\n",
       "        [ 1.5371877, -2.7513578]], dtype=float32)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62c111d",
   "metadata": {
    "papermill": {
     "duration": 0.012981,
     "end_time": "2023-08-20T04:18:33.193784",
     "exception": false,
     "start_time": "2023-08-20T04:18:33.180803",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a647d39d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:18:33.218902Z",
     "iopub.status.busy": "2023-08-20T04:18:33.218217Z",
     "iopub.status.idle": "2023-08-20T04:18:33.226086Z",
     "shell.execute_reply": "2023-08-20T04:18:33.225015Z"
    },
    "papermill": {
     "duration": 0.022735,
     "end_time": "2023-08-20T04:18:33.228123",
     "exception": false,
     "start_time": "2023-08-20T04:18:33.205388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert the list of predictions to a numpy array.\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "# Get the indices of the top 3 predictions for each question.\n",
    "top_three_indices = (-predictions).argsort(axis = 1)[:, :3].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "827f2841",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:18:33.254097Z",
     "iopub.status.busy": "2023-08-20T04:18:33.253012Z",
     "iopub.status.idle": "2023-08-20T04:18:33.260765Z",
     "shell.execute_reply": "2023-08-20T04:18:33.259804Z"
    },
    "papermill": {
     "duration": 0.022871,
     "end_time": "2023-08-20T04:18:33.262763",
     "exception": false,
     "start_time": "2023-08-20T04:18:33.239892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 1, 4], [2, 4, 0], [0, 2, 1], [0, 2, 1], [4, 2, 3], [1, 2, 4], [4, 0, 1], [3, 0, 1], [2, 3, 1], [0, 2, 4], [2, 1, 0], [0, 3, 1], [2, 1, 4], [4, 1, 3], [1, 2, 3], [1, 0, 2], [3, 1, 4], [4, 0, 3], [0, 3, 1], [4, 2, 0], [3, 1, 4], [3, 2, 4], [2, 0, 4], [2, 1, 4], [4, 0, 3], [4, 0, 3], [0, 3, 2], [3, 1, 2], [4, 1, 0], [2, 1, 3], [1, 2, 0], [4, 2, 3], [4, 3, 1], [1, 3, 4], [4, 3, 0], [1, 3, 4], [1, 2, 0], [0, 3, 4], [4, 3, 0], [2, 0, 4], [4, 1, 0], [4, 1, 0], [1, 4, 3], [2, 0, 4], [0, 3, 1], [0, 1, 3], [1, 4, 2], [2, 3, 0], [3, 2, 0], [1, 4, 3], [1, 3, 0], [4, 3, 2], [2, 0, 4], [0, 2, 4], [1, 0, 3], [0, 3, 2], [2, 3, 1], [2, 1, 0], [0, 3, 4], [1, 3, 2], [1, 2, 0], [3, 4, 1], [2, 0, 3], [2, 1, 4], [3, 0, 1], [4, 3, 0], [2, 0, 3], [4, 3, 1], [2, 4, 3], [3, 0, 4], [0, 2, 1], [0, 4, 1], [3, 0, 4], [1, 2, 3], [3, 0, 4], [0, 1, 3], [3, 2, 0], [1, 4, 2], [2, 4, 3], [4, 0, 2], [3, 2, 4], [0, 4, 2], [4, 2, 1], [0, 3, 2], [2, 4, 0], [2, 3, 1], [3, 4, 2], [4, 1, 2], [2, 4, 0], [3, 1, 0], [3, 1, 0], [1, 2, 3], [2, 1, 4], [4, 3, 1], [4, 1, 3], [2, 4, 1], [2, 3, 4], [4, 2, 1], [3, 2, 1], [2, 3, 4], [3, 4, 1], [1, 3, 0], [2, 0, 4], [1, 4, 3], [3, 4, 1], [3, 1, 2], [0, 4, 2], [3, 2, 1], [3, 0, 4], [2, 3, 0], [4, 2, 1], [3, 1, 0], [0, 3, 2], [1, 0, 4], [3, 0, 2], [4, 0, 1], [1, 4, 3], [4, 2, 3], [3, 2, 1], [0, 1, 2], [2, 0, 4], [2, 4, 0], [1, 4, 2], [0, 4, 3], [1, 0, 4], [3, 4, 2], [1, 3, 4], [2, 1, 4], [1, 4, 2], [4, 3, 1], [4, 1, 0], [4, 2, 3], [4, 2, 3], [1, 3, 2], [0, 3, 2], [4, 1, 3], [0, 1, 3], [1, 0, 3], [2, 3, 1], [0, 3, 2], [2, 3, 0], [4, 2, 3], [3, 4, 1], [3, 0, 2], [3, 4, 1], [3, 2, 4], [4, 3, 2], [0, 1, 3], [1, 2, 3], [4, 2, 0], [2, 1, 0], [4, 2, 1], [2, 0, 1], [3, 2, 0], [4, 2, 1], [0, 2, 4], [0, 1, 4], [1, 3, 0], [4, 0, 3], [4, 1, 2], [1, 2, 4], [3, 2, 4], [3, 2, 0], [1, 3, 0], [1, 2, 4], [3, 2, 1], [1, 4, 2], [3, 1, 0], [4, 2, 1], [0, 2, 3], [1, 2, 0], [4, 1, 0], [4, 2, 1], [2, 3, 0], [2, 0, 4], [2, 4, 0], [4, 0, 2], [3, 2, 1], [1, 2, 4], [1, 4, 2], [4, 3, 2], [2, 3, 4], [2, 3, 0], [3, 0, 2], [3, 2, 1], [0, 3, 4], [2, 3, 1], [1, 2, 0], [1, 2, 3], [2, 1, 4], [4, 2, 1], [3, 2, 4], [3, 1, 4], [1, 2, 0], [1, 0, 2], [4, 2, 0], [1, 4, 2], [4, 1, 3], [2, 1, 3], [3, 2, 0]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the extracted values.\n",
    "top_values = []\n",
    "\n",
    "# Loop over all elements in the 'top_three_indices' list.\n",
    "for i in range(len(top_three_indices)):\n",
    "    # Use a list comprehension to extract the second element (index 1) from each sublist.\n",
    "    # This will create a new list 'values' containing these three elements.\n",
    "    values = [top_three_indices[i][j][1] for j in range(3)]\n",
    "    # Append this new list to our 'top_values' list.\n",
    "    top_values.append(values)\n",
    "\n",
    "# Print the resulting list of lists.\n",
    "print(top_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecb3ca35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:18:33.287768Z",
     "iopub.status.busy": "2023-08-20T04:18:33.286950Z",
     "iopub.status.idle": "2023-08-20T04:18:33.294788Z",
     "shell.execute_reply": "2023-08-20T04:18:33.293790Z"
    },
    "papermill": {
     "duration": 0.022548,
     "end_time": "2023-08-20T04:18:33.296929",
     "exception": false,
     "start_time": "2023-08-20T04:18:33.274381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D B E', 'C E A', 'A C B', 'A C B', 'E C D']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a mapping from indices to labels.\n",
    "index_to_label = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E'}\n",
    "\n",
    "# Convert the top three indices to the required format (labels separated by spaces).\n",
    "top_three_labels = [' '.join([index_to_label[idx] for idx in sublist]) for sublist in top_values]\n",
    "top_three_labels[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "188f0b76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:18:33.321721Z",
     "iopub.status.busy": "2023-08-20T04:18:33.320855Z",
     "iopub.status.idle": "2023-08-20T04:18:33.336373Z",
     "shell.execute_reply": "2023-08-20T04:18:33.335393Z"
    },
    "papermill": {
     "duration": 0.029994,
     "end_time": "2023-08-20T04:18:33.338530",
     "exception": false,
     "start_time": "2023-08-20T04:18:33.308536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new DataFrame for the submission.\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'prediction': top_three_labels\n",
    "})\n",
    "\n",
    "# Save the submission DataFrame to a .csv file.\n",
    "submission_df.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cf03adb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T04:18:33.363226Z",
     "iopub.status.busy": "2023-08-20T04:18:33.362611Z",
     "iopub.status.idle": "2023-08-20T04:18:33.373662Z",
     "shell.execute_reply": "2023-08-20T04:18:33.372747Z"
    },
    "papermill": {
     "duration": 0.025983,
     "end_time": "2023-08-20T04:18:33.376144",
     "exception": false,
     "start_time": "2023-08-20T04:18:33.350161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>D B E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>C E A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A C B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A C B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>E C D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>E C A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>B E C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>E B D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>C B D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>D C A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id prediction\n",
       "0      0      D B E\n",
       "1      1      C E A\n",
       "2      2      A C B\n",
       "3      3      A C B\n",
       "4      4      E C D\n",
       "..   ...        ...\n",
       "195  195      E C A\n",
       "196  196      B E C\n",
       "197  197      E B D\n",
       "198  198      C B D\n",
       "199  199      D C A\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142f0b48",
   "metadata": {
    "papermill": {
     "duration": 0.011614,
     "end_time": "2023-08-20T04:18:33.400681",
     "exception": false,
     "start_time": "2023-08-20T04:18:33.389067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "**You will understand the basic concept as to the use of LLMs with the data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cba9df2",
   "metadata": {
    "papermill": {
     "duration": 0.014691,
     "end_time": "2023-08-20T04:18:33.427215",
     "exception": false,
     "start_time": "2023-08-20T04:18:33.412524",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I am a medical doctor working on **artificial intelligence (AI) for medicine**. At present AI is also widely used in the medical field. Particularly, AI performs in the healthcare sector following tasks: **image classification, object detection, semantic segmentation, GANs, text classification, etc**. **If you are interested in AI for medicine, please see my other notebooks.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2816.285453,
   "end_time": "2023-08-20T04:18:36.901525",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-20T03:31:40.616072",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
